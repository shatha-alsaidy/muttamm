{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --q --upgrade langchain pdfplumber langgraph openai chromadb huggingface-hub langchain-experimental  \\\n",
        "    sentence-transformers langchain-community fastapi uvicorn pyngrok \\\n",
        "    httpx tiktoken openai-whisper pydub elevenlabs python-docx pandas tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrjyOOg5NraS",
        "outputId": "1471ad5c-90b8-4384-bfc2-cf7566754401"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# system packages for audio conversion\n",
        "!apt-get update -y && apt-get install -y ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWpsVseXNsSw",
        "outputId": "0dd5eed2-8c0d-4ab2-f961-52b87ac9abbc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,157 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,498 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,222 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,535 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,870 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,592 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,008 kB]\n",
            "Get:22 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,839 kB]\n",
            "Fetched 37.5 MB in 8s (4,851 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from docx import Document\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from langchain_community.document_loaders import PDFPlumberLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "import json\n",
        "import sqlite3\n",
        "import time\n",
        "import re\n",
        "import base64\n",
        "import logging\n",
        "from io import BytesIO\n",
        "from typing import TypedDict, Optional, List, Dict, Any\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from openai import OpenAI\n",
        "import whisper\n",
        "from tiktoken import encoding_for_model"
      ],
      "metadata": {
        "id": "z5-2dFZiNvjI"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.getLogger(\"pdfminer\").setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "nT-3IICWU1-U"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_docx(path: str):\n",
        "    doc = Document(path)\n",
        "    paragraphs = [p.text.strip() for p in doc.paragraphs if p.text.strip()]\n",
        "\n",
        "    tables = []\n",
        "    for table in doc.tables:\n",
        "        rows = []\n",
        "        for r in table.rows:\n",
        "            row = [c.text.strip() for c in r.cells]\n",
        "            rows.append(row)\n",
        "        df = pd.DataFrame(rows)\n",
        "        tables.append(df)\n",
        "    return paragraphs, tables\n",
        "\n",
        "# Convert tables to semantic text\n",
        "def table_to_text(df: pd.DataFrame) -> str:\n",
        "    lines = []\n",
        "    cols = list(df.columns)\n",
        "    for _, row in df.iterrows():\n",
        "        pairs = []\n",
        "        for i, val in enumerate(row):\n",
        "            header = cols[i] if i < len(cols) else f\"Column{i+1}\"\n",
        "            val = str(val).strip()\n",
        "            if val:\n",
        "                pairs.append(f\"{header}: {val}\")\n",
        "        if pairs:\n",
        "            lines.append(\" | \".join(pairs))\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def combine_text(paragraphs, table_texts):\n",
        "    # Combine paragraphs and tables\n",
        "    all_texts = \"\"\n",
        "    for i, p in enumerate(paragraphs):\n",
        "        all_texts += p + \"\\n\"\n",
        "    for i, t in enumerate(table_texts):\n",
        "        all_texts += f\"\\nTable {i+1}:\\n{t}\""
      ],
      "metadata": {
        "id": "NHwr-YW43Hi7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Load PDFs ==========\n",
        "pdf_files = [\"/content/Absher_UserGuide.pdf\", \"/content/الأمن+العام+-+دليل+خدمة+إصدار+رخصة+القيادة.pdf\",\n",
        "             \"/content/خدمة+إصدار+جواز+السفر.pdf\", \"/content/خدمة+تجديد+الهوية+الوطنية.pdf\"]\n",
        "docs = []\n",
        "\n",
        "for pdf in pdf_files:\n",
        "    loader = PDFPlumberLoader(pdf)\n",
        "    docs.extend(loader.load())\n",
        "\n",
        "print(\"Loaded pages:\", len(docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66IcAI1cMOAT",
        "outputId": "e96ee250-3656-43ed-fc6e-36890278ea01"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pages: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Split text ==========\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=200)\n",
        "chunks = splitter.split_documents(docs)\n",
        "print(\"Total chunks:\", len(chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cBWWIW9Nv6J",
        "outputId": "aa1f2d7a-9d21-4c3f-98a5-43743354e8f1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger(\"muttamm_agent\")\n",
        "logger.setLevel(logging.INFO)\n",
        "logging.getLogger(\"uvicorn\").setLevel(logging.WARNING)\n",
        "\n",
        "# ========== CONFIG ==========\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
        "ELEVENLABS_API_KEY = os.environ.get(\"ELEVENLABS_API_KEY\", \"\")\n",
        "ELEVENLABS_VOICE_ID = os.environ.get(\"ELEVENLABS_VOICE_ID\", \"\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "tgrG1u7RN2lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Models & Clients ==========\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Embeddings\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
        "\n",
        "# Whisper\n",
        "try:\n",
        "    whisper_model = whisper.load_model(\"large-v3\")\n",
        "except Exception as e:\n",
        "    logger.warning(\"Failed to load whisper large-v3 locally; try 'large' or use OpenAI STT API. Error: %s\", e)\n",
        "    whisper_model = whisper.load_model(\"large\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFUf51mvOB-Y",
        "outputId": "d8a5855e-5f16-42b3-9d7c-bdbe3e2328d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2180003962.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector database\n",
        "persist_dir = \"./chroma_db\"\n",
        "\n",
        "# Convert chunks into Document objects\n",
        "docs = [Document(page_content=text, metadata={\"chunk_id\": i}) for i, text in enumerate(chunks)]\n",
        "\n",
        "vectordb = Chroma.from_documents(docs, embedding_model, persist_directory=persist_dir)"
      ],
      "metadata": {
        "id": "quriYfdhOJo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Tools: SQL retrievals & Actions ==========\n",
        "def _call_tool_use_llm(context: str, user_message: str, order_number: Optional[str], tool_options: Dict[str, str]) -> str:\n",
        "    \"\"\"\n",
        "    Uses the LLM to decide which tool function to execute based on user context.\n",
        "    Returns the name of the function to be called.\n",
        "    \"\"\"\n",
        "\n",
        "    # Format the tool options for the LLM\n",
        "    tool_descriptions = \"\\n\".join([f\" - {name}: {description}\" for name, description in tool_options.items()])\n",
        "\n",
        "    prompt_for_call = (\n",
        "        \"You are a function-calling expert for Muttamm, the Absher Intelligent Agent.\\n\"\n",
        "        \"Your job is to analyze the user's message and select **one** function that best helps \"\n",
        "        \"with a government service task.\\n\"\n",
        "        \"\\n\"\n",
        "        \"Guidelines:\\n\"\n",
        "        \"- Choose ONLY the single most relevant function.\\n\"\n",
        "        \"- Return ONLY the function name (e.g., check_passport_status)\\n\"\n",
        "        \"- DO NOT return arguments, explanations, or quotes.\\n\"\n",
        "        \"- If no available function fits the user request, respond with: NO_TOOL_NEEDED.\\n\"\n",
        "        \"\\n\"\n",
        "        \"Available Functions:\\n\"\n",
        "        f\"{tool_descriptions}\\n\"\n",
        "        \"\\n\"\n",
        "        f\"Request ID (if any): {request_id}\\n\"\n",
        "        f\"Conversation Context:\\n{context}\\n\\n\"\n",
        "        f\"User Message:\\n{user_message}\\n\\n\"\n",
        "        \"Return the function name to call:\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        resp = openai_client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\":\"user\",\"content\": prompt_for_call}],\n",
        "            temperature=0.0,\n",
        "            max_tokens=50\n",
        "        )\n",
        "        return resp.choices[0].message.content.strip().replace('\"', '').replace(\"'\", \"\")\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Tool LLM decision failed: {e}\")\n",
        "        return \"NO_TOOL_NEEDED\""
      ],
      "metadata": {
        "id": "lXyogDX1O1Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Knowledge Retriever ==========\n",
        "def knowledge_retriever(query: str, k: int = 10) -> List[str]:\n",
        "    global vectordb\n",
        "    if vectordb is None:\n",
        "        return []\n",
        "    try:\n",
        "        results = vectordb.similarity_search(query, k=k)\n",
        "        return [r.page_content for r in results] if results else []\n",
        "    except Exception as e:\n",
        "        logger.warning(\"Chroma retrieval error: %s\", e)\n",
        "        return []\n",
        "\n",
        "# ========== Vision analysis helper  ==========\n",
        "def gpt4o_image_analyze(image_bytes: bytes, caption: str = \"\") -> str:\n",
        "    b64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "    data_uri = f\"data:image/jpeg;base64,{b64}\"\n",
        "    prompt_text = (\n",
        "        \"You are an assistant that analyzes user-submitted images related to Absher services (e.g., ID cards, passports, residency permits, official documents, supporting files, or photos relevant to a service request).\"\n",
        "            \"Your duties:\"\n",
        "            \"1. Provide a clear general description of the image or document.\"\n",
        "            \"2. Identify whether the document appears complete and readable (no missing sections, no major obstructions, no severe blur).\"\n",
        "            \"3. Extract any visible textual fields relevant to Absher workflows (e.g., ID number, passport number, name, expiry dates, residency number, reference numbers, etc.).\"\n",
        "            \"4. Detect any potential issues unrelated to technical specifications (e.g., cropped information, illegible text, obstructed fields, mismatched document type).\"\n",
        "            \"5. Assess whether the document seems appropriate for the intended service.\"\n",
        "            \"6. Output:\"\n",
        "              \"- A concise English summary.\"\n",
        "              \"- A structured JSON object with the following keys:\"\n",
        "                \"- summary\"\n",
        "                \"- issues_found\"\n",
        "                \"- issues_details\"\n",
        "                \"- extracted_fields\"\n",
        "                \"- approval_status (ready / needs_fix / unusable)\"\n",
        "                \"- confidence (0–1)\"\n",
        "            f\"Caption: {caption}\"\n",
        "    )\n",
        "    resp = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You analyze images and produce structured outputs.\"},\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\":\"text\",\"text\": prompt_text},\n",
        "                {\"type\":\"image_url\",\"image_url\": {\"url\": data_uri}}\n",
        "            ]}\n",
        "        ],\n",
        "        temperature=0.0,\n",
        "    )\n",
        "    txt = resp.choices[0].message.content.strip()\n",
        "    return txt\n",
        "\n",
        "# ========== Speech (Whisper) ==========\n",
        "def transcribe_audio_bytes(audio_bytes: bytes) -> str:\n",
        "    tmp_path = \"/content/temp_audio.ogg\"\n",
        "    with open(tmp_path, \"wb\") as f:\n",
        "        f.write(audio_bytes)\n",
        "    try:\n",
        "        res = whisper_model.transcribe(tmp_path, language=\"ar\")\n",
        "        return res.get(\"text\",\"\").strip()\n",
        "    except Exception as e:\n",
        "        logger.warning(\"Whisper local transcribe failed: %s\", e)\n",
        "        # fallback try without forcing language\n",
        "        res = whisper_model.transcribe(tmp_path)\n",
        "        return res.get(\"text\",\"\").strip()\n",
        "\n",
        "# ========== ElevenLabs TTS ==========\n",
        "async def tts_elevenlabs_arabic(text: str) -> bytes:\n",
        "    url = f\"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}\"\n",
        "    headers = {\"xi-api-key\": ELEVENLABS_API_KEY, \"Content-Type\": \"application/json\"}\n",
        "    payload = {\"text\": text, \"voice_settings\": {\"stability\":0.6,\"similarity_boost\":0.6}}\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        r = await client.post(url, headers=headers, json=payload, timeout=120)\n",
        "        r.raise_for_status()\n",
        "        return r.content"
      ],
      "metadata": {
        "id": "Eem6nD9zPEY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Prompts ==========\n",
        "EMOTION_PROMPT = \"\"\"You are a short Arabic emotion classifier specialized on Saudi dialect.\n",
        "Given this user message (Arabic), answer with one word: angry, frustrated, neutral, satisfied, grateful.\n",
        "answer angry only if the user is very very angry, given an anger score of 4/5 or 5/5, and wait a bit for how the conversation turns out before answering angry.\n",
        "Only return the word.\"\"\"\n",
        "\n",
        "INTENT_PROMPT = \"\"\"You are a classifier for Absher-related government services.\n",
        "Given the Arabic (Saudi dialect) message, classify it into exactly one of:\n",
        "\n",
        "[الأحوال المدنية, الجوازات, المرور, شؤون الوافدين]\n",
        "\n",
        "Choose the category that best matches the user’s request, even if indirect.\n",
        "Return only the category name.\n",
        "\"\"\"\n",
        "\n",
        "RESPONSE_PROMPT_TEMPLATE = \"\"\"\n",
        "You are Muttamm, a smart assistant that helps users navigate Saudi government services covering four main categories\n",
        "(الأحوال المدنية، الجوازات، المرور، شؤون الوافدين).\n",
        "\n",
        "Guidelines:\n",
        "- Always respond in clear Saudi dialect.\n",
        "- Provide direct, practical steps that match the user’s request.\n",
        "- Use information from `context` naturally without sounding robotic.\n",
        "- If an image was analyzed, acknowledge what was detected and connect it to the user’s need.\n",
        "- Avoid unnecessary apologies; be calm and reassuring.\n",
        "- If the user is angry or frustrated, begin with empathy and then guide them clearly.\n",
        "- If you asked for missing info earlier, integrate the user's reply smoothly and continue the workflow.\n",
        "- Escalate to a human officer only when required and after exhausting your available steps.\n",
        "- Keep responses short (2–4 natural sentences), helpful, and fit the tone of government service support.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "User message:\n",
        "{user_message}\n",
        "\n",
        "Emotion: {emotion}\n",
        "Detected Category: {intent}\n",
        "\n",
        "Produce the final answer in Saudi Arabic.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "r-pzBn0WPThV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- State schema ----------------\n",
        "class MuttammState(TypedDict):\n",
        "    user_id: str\n",
        "    user_first_message: Optional[str]\n",
        "    user_current_message: Optional[str]\n",
        "    chat_history: List[Dict[str,str]]\n",
        "    message_type: Optional[str]\n",
        "    extracted_text: Optional[str]\n",
        "    emotion: Optional[str]\n",
        "    intent: Optional[str]\n",
        "    service_name: Optional[str]\n",
        "    collected_info: Dict[str, Any]\n",
        "    pending_task: Optional[str]\n",
        "    sql_result: Optional[Any]\n",
        "    retrieved_context: Optional[List[str]]\n",
        "    escalate: bool\n",
        "    unsolved_count: int\n",
        "    final_response: Optional[str]\n",
        "    voice_bytes: Optional[bytes]\n",
        "    image_bytes: Optional[bytes]\n",
        "    image_caption: Optional[str]\n",
        "    reply_with_voice: bool"
      ],
      "metadata": {
        "id": "OXe5T1--PdwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- LangGraph nodes ----------------\n",
        "def detect_input_type_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "\n",
        "    mtype = state.get(\"message_type\")\n",
        "\n",
        "    # ALWAYS reset voice reply flag\n",
        "    updates[\"reply_with_voice\"] = (mtype == \"voice\")\n",
        "    if mtype == \"text\":\n",
        "        updates[\"extracted_text\"] = state.get(\"user_current_message\",\"\")\n",
        "    return updates\n",
        "\n",
        "def speech_to_text_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "    if state.get(\"message_type\") == \"voice\" and state.get(\"voice_bytes\"):\n",
        "        updates[\"reply_with_voice\"] = True\n",
        "        text = transcribe_audio_bytes(state[\"voice_bytes\"])\n",
        "        updates[\"extracted_text\"] = text\n",
        "        new_history = state[\"chat_history\"] + [{\"role\":\"agent\",\"content\": text}]\n",
        "        updates[\"chat_history\"] = new_history\n",
        "        updates[\"message_type\"] = \"text\"\n",
        "    return updates\n",
        "\n",
        "def vision_analyzer_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "    if state.get(\"message_type\") == \"image\" and state.get(\"image_bytes\"):\n",
        "        try:\n",
        "            desc = gpt4o_image_analyze(state[\"image_bytes\"], caption=state.get(\"image_caption\",\"\"))\n",
        "            updates[\"extracted_text\"] = desc\n",
        "            new_history = state[\"chat_history\"] + [{\"role\":\"agent\",\"content\": f\"[image_analysis]{desc}\"}]\n",
        "            updates[\"chat_history\"] = new_history\n",
        "            updates[\"message_type\"] = \"text\"\n",
        "        except Exception as e:\n",
        "            logger.warning(\"vision analyze error: %s\", e)\n",
        "    return updates\n",
        "\n",
        "def emotion_detection_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "    txt = state.get(\"extracted_text\",\"\")\n",
        "    if not txt:\n",
        "        return updates\n",
        "    try:\n",
        "        resp = openai_client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\":\"system\",\"content\":\"You are a concise classifier.\"},\n",
        "                      {\"role\":\"user\",\"content\": EMOTION_PROMPT + \"\\n\\nMessage:\\n\" + txt}],\n",
        "            temperature=0.0\n",
        "        )\n",
        "        out = resp.choices[0].message.content.strip().lower()\n",
        "    except Exception as e:\n",
        "        logger.warning(\"Emotion LLM error: %s\", e)\n",
        "        out = \"\"\n",
        "    if out not in [\"angry\",\"frustrated\",\"neutral\",\"satisfied\",\"grateful\"]:\n",
        "        if any(k in txt for k in [\"غضب\",\"غاضب\",\"مغتاظ\",\"مستاء\"]):\n",
        "            out = \"angry\"\n",
        "        else:\n",
        "            out = \"neutral\"\n",
        "    updates[\"emotion\"] = out\n",
        "    return updates\n",
        "\n",
        "def pre_escalation_check_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "    if state.get(\"emotion\") == \"angry\":\n",
        "        updates[\"escalate\"] = True\n",
        "    return updates\n",
        "\n",
        "def intent_classification_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "    txt = state.get(\"extracted_text\",\"\")\n",
        "    if not txt:\n",
        "        return updates\n",
        "    try:\n",
        "        resp = openai_client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\":\"system\",\"content\":\"You are a short intent classifier.\"},\n",
        "                      {\"role\":\"user\",\"content\": INTENT_PROMPT + \"\\n\\nMessage:\\n\" + txt}],\n",
        "            temperature=0.0\n",
        "        )\n",
        "        intent = resp.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        logger.warning(\"Intent LLM error: %s\", e)\n",
        "        intent = \"\"\n",
        "    possible = [\"الأحوال المدنية\", \"الجوازات\", \"المرور\", \"شؤون الوافدين\"]\n",
        "\n",
        "    if intent not in possible:\n",
        "        t = txt.lower()\n",
        "\n",
        "        # الأحوال المدنية – Civil Affairs\n",
        "        if any(w in t for w in [\n",
        "            \"هوية\", \"بطاقة\", \"سجل\", \"أسرة\", \"بدل فاقد\", \"بدل تالف\",\n",
        "            \"مولود\", \"وفاة\", \"تعديل مهنة\", \"تحديث\", \"الأحوال\"\n",
        "        ]):\n",
        "            intent = \"الأحوال المدنية\"\n",
        "\n",
        "        # الجوازات – Passports\n",
        "        elif any(w in t for w in [\n",
        "            \"جواز\", \"جوازات\", \"تجديد جواز\", \"خروج وعودة\", \"تمديد\",\n",
        "            \"هوية مقيم\", \"الإقامة\", \"نقل خدمات\", \"تأشيرة\"\n",
        "        ]):\n",
        "            intent = \"الجوازات\"\n",
        "\n",
        "        # المرور – Traffic\n",
        "        elif any(w in t for w in [\n",
        "            \"رخصة\", \"قيادة\", \"استمارة\", \"تفويض\", \"حادث\", \"مخالفة\",\n",
        "            \"المرور\", \"نقل ملكية\", \"تجديد استمارة\"\n",
        "        ]):\n",
        "            intent = \"المرور\"\n",
        "\n",
        "        # شؤون الوافدين – Expatriate Affairs\n",
        "        elif any(w in t for w in [\n",
        "            \"وافد\", \"كفيل\", \"نقل كفالة\", \"بلاغ هروب\", \"تأشيرة عمل\",\n",
        "            \"تعديل مهنة عامل\", \"إلغاء هروب\"\n",
        "        ]):\n",
        "            intent = \"شؤون الوافدين\"\n",
        "\n",
        "        # Default fallback\n",
        "        else:\n",
        "            intent = \"الأحوال المدنية\"\n",
        "        updates[\"intent\"] = intent\n",
        "        return updates\n",
        "\n",
        "def router_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "    if state.get(\"escalate\"):\n",
        "        updates[\"pending_task\"] = \"escalate\"\n",
        "        return updates\n",
        "    updates[\"pending_task\"] = state.get(\"intent\",\"Other\")\n",
        "    return updates\n",
        "\n",
        "# Sub-agent nodes\n",
        "def ahwal_subagent_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "    text = state.get(\"extracted_text\", \"\")\n",
        "    service = detect_specific_service(text)\n",
        "\n",
        "    # 1. Ask for missing required info\n",
        "    missing = required_info_missing(\"ahwal\", service, state[\"collected_info\"])\n",
        "    if missing:\n",
        "        new_history = state[\"chat_history\"] + [{\n",
        "            \"role\": \"agent\",\n",
        "            \"content\": f\"علشان أقدر أساعدك بدقة، احتاج منك: {missing}\"\n",
        "        }]\n",
        "        updates[\"chat_history\"] = new_history\n",
        "        updates[\"pending_task\"] = \"await_missing_info\"\n",
        "        return updates\n",
        "\n",
        "    # 2. Define available tools for الأحوال المدنية\n",
        "    ahwal_tools = {\n",
        "        \"get_id_expiry\": \"Retrieves ID expiration date.\",\n",
        "        \"get_id_status\": \"Retrieves the national ID validity/status.\",\n",
        "        \"get_ahwal_requirements\": \"Retrieves official requirements for this service.\"\n",
        "    }\n",
        "\n",
        "    # 3. LLM picks best tool\n",
        "    context = \"\\n\".join([f\"{m['role']}: {m['content']}\"\n",
        "                         for m in state[\"chat_history\"][-4:]])\n",
        "    tool_name = _call_tool_use_llm(context, text, service, ahwal_tools)\n",
        "\n",
        "    # 4. Execute tool\n",
        "    try:\n",
        "        if tool_name == \"get_id_expiry\":\n",
        "            data = get_id_expiry(state[\"user_id\"])\n",
        "        elif tool_name == \"get_id_status\":\n",
        "            data = get_id_status(state[\"user_id\"])\n",
        "        else:\n",
        "            data = get_ahwal_requirements(service)\n",
        "    except Exception as e:\n",
        "        data = {\"error\": f\"Error executing tool: {str(e)}\"}\n",
        "\n",
        "    updates[\"sql_result\"] = data\n",
        "\n",
        "    # Update history\n",
        "    updates[\"chat_history\"] = state[\"chat_history\"] + [{\n",
        "        \"role\": \"agent\",\n",
        "        \"content\": \"أتحقق لك الآن من البيانات\"\n",
        "    }]\n",
        "    return updates\n",
        "\n",
        "\n",
        "def jawazat_subagent_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "    text = state.get(\"extracted_text\", \"\")\n",
        "    service = detect_specific_service(text)\n",
        "\n",
        "    missing = required_info_missing(\"jawazat\", service, state[\"collected_info\"])\n",
        "    if missing:\n",
        "        updates[\"chat_history\"] = state[\"chat_history\"] + [{\n",
        "            \"role\": \"agent\",\n",
        "            \"content\": f\"ممتاز، بس قبل أكمل احتاج منك: {missing}\"\n",
        "        }]\n",
        "        updates[\"pending_task\"] = \"await_missing_info\"\n",
        "        return updates\n",
        "\n",
        "    jawazat_tools = {\n",
        "        \"get_passport_expiry\": \"Returns passport expiration date.\",\n",
        "        \"get_passport_status\": \"Returns passport validity & travel eligibility.\",\n",
        "        \"get_jawazat_requirements\": \"Steps & requirements for the selected service.\"\n",
        "    }\n",
        "\n",
        "    context = \"\\n\".join([f\"{m['role']}: {m['content']}\"\n",
        "                         for m in state[\"chat_history\"][-4:]])\n",
        "    tool_name = _call_tool_use_llm(context, text, service, jawazat_tools)\n",
        "\n",
        "    try:\n",
        "        if tool_name == \"get_passport_expiry\":\n",
        "            data = get_passport_expiry(state[\"user_id\"])\n",
        "        elif tool_name == \"get_passport_status\":\n",
        "            data = get_passport_status(state[\"user_id\"])\n",
        "        else:\n",
        "            data = get_jawazat_requirements(service)\n",
        "    except Exception as e:\n",
        "        data = {\"error\": f\"Error executing tool: {str(e)}\"}\n",
        "\n",
        "    updates[\"sql_result\"] = data\n",
        "\n",
        "    updates[\"chat_history\"] = state[\"chat_history\"] + [{\n",
        "        \"role\": \"agent\",\n",
        "        \"content\": \"أشيّك على بيانات الجواز الحين…\"\n",
        "    }]\n",
        "    return updates\n",
        "\n",
        "\n",
        "def murur_subagent_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "    text = state.get(\"extracted_text\", \"\")\n",
        "    service = detect_specific_service(text)\n",
        "\n",
        "    missing = required_info_missing(\"murur\", service, state[\"collected_info\"])\n",
        "    if missing:\n",
        "        updates[\"chat_history\"] = state[\"chat_history\"] + [{\n",
        "            \"role\": \"agent\",\n",
        "            \"content\": f\"بس نحتاج منك هذي المعلومة أول: {missing}\"\n",
        "        }]\n",
        "        updates[\"pending_task\"] = \"await_missing_info\"\n",
        "        return updates\n",
        "\n",
        "    murur_tools = {\n",
        "        \"get_license_status\": \"Returns driver's license validity and expiry.\",\n",
        "        \"get_vehicle_info\": \"Returns vehicle ownership and expiration info.\",\n",
        "        \"get_violations\": \"Lists traffic violations with details.\"\n",
        "    }\n",
        "\n",
        "    context = \"\\n\".join([f\"{m['role']}: {m['content']}\"\n",
        "                         for m in state[\"chat_history\"][-4:]])\n",
        "    tool_name = _call_tool_use_llm(context, text, service, murur_tools)\n",
        "\n",
        "    try:\n",
        "        if tool_name == \"get_license_status\":\n",
        "            data = get_license_status(state[\"user_id\"])\n",
        "        elif tool_name == \"get_vehicle_info\":\n",
        "            data = get_vehicle_info(state[\"user_id\"])\n",
        "        else:\n",
        "            data = get_violations(state[\"user_id\"])\n",
        "    except Exception as e:\n",
        "        data = {\"error\": f\"Error executing tool: {str(e)}\"}\n",
        "\n",
        "    updates[\"sql_result\"] = data\n",
        "    updates[\"chat_history\"] = state[\"chat_history\"] + [{\n",
        "        \"role\": \"agent\",\n",
        "        \"content\": \"ثواني أشيّك لك على بيانات المرور…\"\n",
        "    }]\n",
        "    return updates\n",
        "\n",
        "\n",
        "def wafeedin_subagent_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "    text = state.get(\"extracted_text\", \"\")\n",
        "    service = detect_specific_service(text)\n",
        "\n",
        "    missing = required_info_missing(\"wafeedin\", service, state[\"collected_info\"])\n",
        "    if missing:\n",
        "        updates[\"chat_history\"] = state[\"chat_history\"] + [{\n",
        "            \"role\": \"agent\",\n",
        "            \"content\": f\" {missing} تمام، احتاج عشان أكمل لك.\"\n",
        "        }]\n",
        "        updates[\"pending_task\"] = \"await_missing_info\"\n",
        "        return updates\n",
        "\n",
        "    wafeedin_tools = {\n",
        "        \"get_iqama_status\": \"Returns iqama expiry and validity.\",\n",
        "        \"get_dependents\": \"Returns dependents linked to the user.\",\n",
        "        \"get_exit_reentry_status\": \"Checks exit/re-entry visa validity.\"\n",
        "    }\n",
        "\n",
        "    context = \"\\n\".join([f\"{m['role']}: {m['content']}\"\n",
        "                         for m in state[\"chat_history\"][-4:]])\n",
        "\n",
        "    tool_name = _call_tool_use_llm(context, text, service, wafeedin_tools)\n",
        "\n",
        "    try:\n",
        "        if tool_name == \"get_iqama_status\":\n",
        "            data = get_iqama_status(state[\"user_id\"])\n",
        "        elif tool_name == \"get_dependents\":\n",
        "            data = get_dependents(state[\"user_id\"])\n",
        "        else:\n",
        "            data = get_exit_reentry_status(state[\"user_id\"])\n",
        "    except Exception as e:\n",
        "        data = {\"error\": f\"Error executing tool: {str(e)}\"}\n",
        "\n",
        "    updates[\"sql_result\"] = data\n",
        "    updates[\"chat_history\"] = state[\"chat_history\"] + [{\n",
        "        \"role\": \"agent\",\n",
        "        \"content\": \"أشيّك لك على بيانات الإقامة…\"\n",
        "    }]\n",
        "    return updates\n",
        "\n",
        "\n",
        "def other_subagent_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "    text = state.get(\"extracted_text\", \"\")\n",
        "\n",
        "    kr = knowledge_retriever(text, k=10)\n",
        "    if not kr:\n",
        "        updates[\"chat_history\"] = state[\"chat_history\"] + [{\n",
        "            \"role\": \"agent\",\n",
        "            \"content\": \"تقدر توضّح لي سؤالك أكثر؟\"\n",
        "        }]\n",
        "        updates[\"pending_task\"] = \"await_clarification\"\n",
        "        return updates\n",
        "\n",
        "    updates[\"retrieved_context\"] = kr\n",
        "    return updates\n",
        "\n",
        "def post_handler_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "    if state.get(\"escalate\"):\n",
        "        return updates\n",
        "    sql = state.get(\"sql_result\")\n",
        "    resolved = False\n",
        "    if sql:\n",
        "        if (isinstance(sql, dict) and len(sql)>0) or (isinstance(sql, list) and len(sql)>0):\n",
        "            resolved = True\n",
        "    if not resolved:\n",
        "        updates[\"unsolved_count\"] = state.get(\"unsolved_count\",0) + 1\n",
        "    if state.get(\"unsolved_count\",0) >= 30:\n",
        "        updates[\"escalate\"] = True\n",
        "    return updates\n",
        "\n",
        "def response_generator_node(state: MuttammState) -> MuttammState:\n",
        "    updates = {}\n",
        "    if state.get(\"escalate\"):\n",
        "        final_response = \"حسنًا، سأحوّل محادثتك الآن إلى موظف خدمة العملاء لمتابعة المشكلة. يرجى الانتظار لحظة.\"\n",
        "        updates[\"final_response\"] = final_response\n",
        "        new_history = state[\"chat_history\"] + [{\"role\":\"agent\",\"content\": final_response}]\n",
        "        updates[\"chat_history\"] = new_history\n",
        "        return updates\n",
        "    context_parts = []\n",
        "    if state.get(\"sql_result\"):\n",
        "        context_parts.append(\"SQL results: \" + json.dumps(state[\"sql_result\"], ensure_ascii=False))\n",
        "    if state.get(\"retrieved_context\"):\n",
        "        context_parts.append(\"Knowledge: \" + \" || \".join(state[\"retrieved_context\"]))\n",
        "    recent = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in state.get(\"chat_history\",[])[-6:]])\n",
        "    context = \"\\n\".join(context_parts + [recent])\n",
        "    prompt = RESPONSE_PROMPT_TEMPLATE.format(context=context, user_message=state.get(\"extracted_text\",\"\"), emotion=state.get(\"emotion\",\"\"), intent=state.get(\"intent\",\"\"))\n",
        "    try:\n",
        "        resp = openai_client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\":\"user\",\"content\": prompt}],\n",
        "            temperature=0.3,\n",
        "            max_tokens=500\n",
        "        )\n",
        "        out = resp.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        logger.warning(\"Response generation failed: %s\", e)\n",
        "        out = \"عذرًا، حدث خطأ أثناء تجهيز الرد. سأحوّل المحادثة لموظف خدمة العملاء.\"\n",
        "        updates[\"escalate\"] = True\n",
        "    updates[\"final_response\"] = out\n",
        "    new_history = state[\"chat_history\"] + [{\"role\":\"agent\",\"content\": out}]\n",
        "    updates[\"chat_history\"] = new_history\n",
        "\n",
        "    return updates\n",
        "\n",
        "def task_router(state):\n",
        "    task = state.get(\"pending_task\")\n",
        "    return task"
      ],
      "metadata": {
        "id": "Q2-xp1FOPx10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Build LangGraph with correct conditional routing ----------------\n",
        "workflow = StateGraph(MuttammState)\n",
        "\n",
        "# Core perception & understanding nodes\n",
        "workflow.add_node(\"detect_input_type\", detect_input_type_node)\n",
        "workflow.add_node(\"speech_to_text\", speech_to_text_node)\n",
        "workflow.add_node(\"vision_analyzer\", vision_analyzer_node)\n",
        "workflow.add_node(\"emotion_detection\", emotion_detection_node)\n",
        "workflow.add_node(\"pre_escalation_check\", pre_escalation_check_node)\n",
        "workflow.add_node(\"intent_classification\", intent_classification_node)\n",
        "\n",
        "# Main router node\n",
        "workflow.add_node(\"router\", router_node)\n",
        "\n",
        "# Sub-agents\n",
        "workflow.add_node(\"ahwal_agent\", ahwal_subagent_node)\n",
        "workflow.add_node(\"jawazat_agent\", jawazat_subagent_node)\n",
        "workflow.add_node(\"murur_agent\", murur_subagent_node)\n",
        "workflow.add_node(\"wafeedin_agent\", wafeedin_subagent_node)\n",
        "workflow.add_node(\"other_agent\", other_subagent_node)\n",
        "\n",
        "# Post handler & response\n",
        "workflow.add_node(\"post_handler\", post_handler_node)\n",
        "workflow.add_node(\"response_generator\", response_generator_node)\n",
        "\n",
        "\n",
        "# ---------------- Detect input type router ----------------\n",
        "def detect_input_router(state: MuttammState):\n",
        "    t = state.get(\"message_type\")\n",
        "    if t == \"voice\":\n",
        "        return \"voice\"\n",
        "    if t == \"image\":\n",
        "        return \"image\"\n",
        "    return \"text\"\n",
        "\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"detect_input_type\",\n",
        "    detect_input_router,\n",
        "    {\n",
        "        \"voice\": \"speech_to_text\",\n",
        "        \"image\": \"vision_analyzer\",\n",
        "        \"text\": \"emotion_detection\",\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"speech_to_text\", \"emotion_detection\")\n",
        "workflow.add_edge(\"vision_analyzer\", \"emotion_detection\")\n",
        "workflow.add_edge(\"emotion_detection\", \"pre_escalation_check\")\n",
        "workflow.add_edge(\"pre_escalation_check\", \"intent_classification\")\n",
        "workflow.add_edge(\"intent_classification\", \"router\")\n",
        "\n",
        "\n",
        "# ---------------- Main router for Muttamm ----------------\n",
        "workflow.add_conditional_edges(\n",
        "    \"router\",\n",
        "    task_router,\n",
        "    {\n",
        "        \"أحوال مدنية\": \"ahwal_agent\",\n",
        "        \"جوازات\": \"jawazat_agent\",\n",
        "        \"مرور\": \"murur_agent\",\n",
        "        \"شؤون وافدين\": \"wafeedin_agent\",\n",
        "        \"Other\": \"other_agent\",\n",
        "        \"escalate\": \"response_generator\",\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# ---------------- Sub-agent → Post handler ----------------\n",
        "workflow.add_edge(\"ahwal_agent\", \"post_handler\")\n",
        "workflow.add_edge(\"jawazat_agent\", \"post_handler\")\n",
        "workflow.add_edge(\"murur_agent\", \"post_handler\")\n",
        "workflow.add_edge(\"wafeedin_agent\", \"post_handler\")\n",
        "workflow.add_edge(\"other_agent\", \"post_handler\")\n",
        "\n",
        "\n",
        "# ---------------- Post handler → Response generator ----------------\n",
        "workflow.add_edge(\"post_handler\", \"response_generator\")\n",
        "workflow.add_edge(\"response_generator\", END)\n",
        "\n",
        "\n",
        "# ---------------- Entry point ----------------\n",
        "workflow.set_entry_point(\"detect_input_type\")\n",
        "agent_app = workflow.compile()\n"
      ],
      "metadata": {
        "id": "EPa1134eQKix"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}